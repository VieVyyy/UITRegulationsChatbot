{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"5f18c1f9e8f94131a571fadd314829c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa9970c81e154e08ac74fe53cb538a01","IPY_MODEL_607701f95e5d4288aefe431993608ff2","IPY_MODEL_6d2392a0bf2442e99d04dd34339de3e4"],"layout":"IPY_MODEL_bd51c81d0fa44647980c3d9aec73247d"}},"fa9970c81e154e08ac74fe53cb538a01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f43c5fe268a440fea57be709ef36f630","placeholder":"​","style":"IPY_MODEL_037ab15ad8bd4651bcc9cb0634a327de","value":"modules.json: 100%"}},"607701f95e5d4288aefe431993608ff2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6319be4975b4fbe88809424b49c2878","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e90d661c0684b1aae80ad25588f25f8","value":349}},"6d2392a0bf2442e99d04dd34339de3e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_647ac64a4ea74dfbbd6d4e2653c4e07f","placeholder":"​","style":"IPY_MODEL_355f418d4ee246879b93b8faae61b947","value":" 349/349 [00:00&lt;00:00, 36.9kB/s]"}},"bd51c81d0fa44647980c3d9aec73247d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f43c5fe268a440fea57be709ef36f630":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"037ab15ad8bd4651bcc9cb0634a327de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6319be4975b4fbe88809424b49c2878":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e90d661c0684b1aae80ad25588f25f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"647ac64a4ea74dfbbd6d4e2653c4e07f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"355f418d4ee246879b93b8faae61b947":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1502c00d31a40448020eb9beea58c81":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c9cf0ecaac0741199200f54a91befe56","IPY_MODEL_fced18920f3d49f6a314341a03046169","IPY_MODEL_c406465186354c1a945790948f4b6c30"],"layout":"IPY_MODEL_6cf252d11fba40a8997ddb9116cf35bb"}},"c9cf0ecaac0741199200f54a91befe56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48df51d75e1d47bab74e5b11b3b66f21","placeholder":"​","style":"IPY_MODEL_80e76c3c277f41bd8bafc5517b5a2266","value":"config_sentence_transformers.json: 100%"}},"fced18920f3d49f6a314341a03046169":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fae27b221c554d99a8b9c5b6a2627cda","max":123,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c7c6325cb284c5eab68d8df9c0bbd5d","value":123}},"c406465186354c1a945790948f4b6c30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f03c29adeaad4b4db320d905a5382fb5","placeholder":"​","style":"IPY_MODEL_6551501aa8904129ab33811200101aad","value":" 123/123 [00:00&lt;00:00, 14.0kB/s]"}},"6cf252d11fba40a8997ddb9116cf35bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48df51d75e1d47bab74e5b11b3b66f21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80e76c3c277f41bd8bafc5517b5a2266":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fae27b221c554d99a8b9c5b6a2627cda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c7c6325cb284c5eab68d8df9c0bbd5d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f03c29adeaad4b4db320d905a5382fb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6551501aa8904129ab33811200101aad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03524b78ad2a4457843722765639a1f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27ebf65b6450461cb00600cd7ecf8ad2","IPY_MODEL_07c3db1605df4422a96d57f65810aab3","IPY_MODEL_d57afbc944c14fb49db93d1b3b8230cc"],"layout":"IPY_MODEL_188419242c334ce4bdc06a36776f9c7e"}},"27ebf65b6450461cb00600cd7ecf8ad2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a41f9ed409ce4595966989a17ace2ca9","placeholder":"​","style":"IPY_MODEL_e27f8176b8f24dbb81edcf0cc6e9cd87","value":"README.md: "}},"07c3db1605df4422a96d57f65810aab3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dde4edd7bb54d7ab5a1d4bd9978c141","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2c0d1869d9e849218c4dc48518705cc5","value":1}},"d57afbc944c14fb49db93d1b3b8230cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dbffbb107434c1c8557950d75e4735e","placeholder":"​","style":"IPY_MODEL_f2201ae9d5184e3a81209eca24e83b23","value":" 15.8k/? [00:00&lt;00:00, 1.59MB/s]"}},"188419242c334ce4bdc06a36776f9c7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a41f9ed409ce4595966989a17ace2ca9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e27f8176b8f24dbb81edcf0cc6e9cd87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8dde4edd7bb54d7ab5a1d4bd9978c141":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"2c0d1869d9e849218c4dc48518705cc5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2dbffbb107434c1c8557950d75e4735e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2201ae9d5184e3a81209eca24e83b23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96c672117c5c48b3a327ab9a035a114d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ddd94505dd5448db89a31b5ad3fdd50","IPY_MODEL_d9c1a4f1265442698a93b383a39a4347","IPY_MODEL_0fd25e92103c4c419a6530abf026e908"],"layout":"IPY_MODEL_0a283db18eff4036a5ada414ec50e65d"}},"8ddd94505dd5448db89a31b5ad3fdd50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e006f538c314ce69ebc41eca42ca870","placeholder":"​","style":"IPY_MODEL_241d566ef0b54a27859bae6fe4771480","value":"sentence_bert_config.json: 100%"}},"d9c1a4f1265442698a93b383a39a4347":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15f240f83e1e4413a72302bd4eaca940","max":54,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2d0ccf8c3a9b4bbd852d7b0ed6a12ca6","value":54}},"0fd25e92103c4c419a6530abf026e908":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a03be3341495474db1caf98e1ff12b92","placeholder":"​","style":"IPY_MODEL_34d36048b81b4be08f9c838dcf92feb1","value":" 54.0/54.0 [00:00&lt;00:00, 5.82kB/s]"}},"0a283db18eff4036a5ada414ec50e65d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e006f538c314ce69ebc41eca42ca870":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"241d566ef0b54a27859bae6fe4771480":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15f240f83e1e4413a72302bd4eaca940":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d0ccf8c3a9b4bbd852d7b0ed6a12ca6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a03be3341495474db1caf98e1ff12b92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34d36048b81b4be08f9c838dcf92feb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6109530288540ffa19e1a18e82d9c11":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9c00cceef704e089e396c0629341d1a","IPY_MODEL_9c0749d07b164d5ca2867bf24d7cb1e8","IPY_MODEL_b4924d83ab4f4247bce10fc3b402417c"],"layout":"IPY_MODEL_b0e7dc94194d479dafa3f45009903cb6"}},"e9c00cceef704e089e396c0629341d1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25aed4d3cf9047d8a753a17959760a0a","placeholder":"​","style":"IPY_MODEL_eb3b35579633429f877885fab0ffdb3c","value":"config.json: 100%"}},"9c0749d07b164d5ca2867bf24d7cb1e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9596ac6188d145c99dd9723225660c81","max":687,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b180d0cae8264332a9825881af4a25af","value":687}},"b4924d83ab4f4247bce10fc3b402417c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e832bdcd026a4ee099786f7c7053886f","placeholder":"​","style":"IPY_MODEL_a8e4b3d93a4d4737a678ab6601f7ea45","value":" 687/687 [00:00&lt;00:00, 73.8kB/s]"}},"b0e7dc94194d479dafa3f45009903cb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25aed4d3cf9047d8a753a17959760a0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb3b35579633429f877885fab0ffdb3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9596ac6188d145c99dd9723225660c81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b180d0cae8264332a9825881af4a25af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e832bdcd026a4ee099786f7c7053886f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8e4b3d93a4d4737a678ab6601f7ea45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d33a1f1c99c2479e8b8abb88f3384098":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b300ce7e1d734b2d97473d67ed49da4b","IPY_MODEL_f90a061dbe084fb09990302f52b4534d","IPY_MODEL_0af3896c821b4085ad17e00264f77ba0"],"layout":"IPY_MODEL_36984b2d2aab406e8e6dff6daedf4de2"}},"b300ce7e1d734b2d97473d67ed49da4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f763f784f2e14e088db5f805f0362419","placeholder":"​","style":"IPY_MODEL_5a53ab66d5ba4f648717c3a65a85f95d","value":"pytorch_model.bin:  88%"}},"f90a061dbe084fb09990302f52b4534d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e45831add8b424e8c37bdc8a9889dc6","max":2271145830,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5218f4d93bdb4bb88a27f95a395b2848","value":2002929752}},"0af3896c821b4085ad17e00264f77ba0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98d97704b67d4f47b1ec957371ea7d78","placeholder":"​","style":"IPY_MODEL_5d0081d1047b491e89314df326240d51","value":" 2.00G/2.27G [02:09&lt;00:19, 13.6MB/s]"}},"36984b2d2aab406e8e6dff6daedf4de2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f763f784f2e14e088db5f805f0362419":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a53ab66d5ba4f648717c3a65a85f95d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e45831add8b424e8c37bdc8a9889dc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5218f4d93bdb4bb88a27f95a395b2848":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98d97704b67d4f47b1ec957371ea7d78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d0081d1047b491e89314df326240d51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13606847,"sourceType":"datasetVersion","datasetId":8646518},{"sourceId":668805,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":506409,"modelId":521201}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Gỡ bỏ hết\n!pip uninstall -y transformers sentence-transformers accelerate\n\n# 2. Cài đặt bộ phiên bản \"Cổ điển\" (Đã test khớp 100%)\n!pip install \\\n    sentence-transformers==2.7.0 \\\n    transformers==4.44.2 \\\n    accelerate==0.27.2 \\\n    \"numpy<2.0.0\"","metadata":{"id":"_zG1n7Gl2451","outputId":"2c6b5b2b-d078-4782-aba3-d1dfb5435108","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:04:41.212254Z","iopub.execute_input":"2025-12-16T11:04:41.212945Z","iopub.status.idle":"2025-12-16T11:06:02.736609Z","shell.execute_reply.started":"2025-12-16T11:04:41.212912Z","shell.execute_reply":"2025-12-16T11:06:02.735842Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.53.3\nUninstalling transformers-4.53.3:\n  Successfully uninstalled transformers-4.53.3\nFound existing installation: sentence-transformers 4.1.0\nUninstalling sentence-transformers-4.1.0:\n  Successfully uninstalled sentence-transformers-4.1.0\nFound existing installation: accelerate 1.9.0\nUninstalling accelerate-1.9.0:\n  Successfully uninstalled accelerate-1.9.0\nCollecting sentence-transformers==2.7.0\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\nCollecting transformers==4.44.2\n  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate==0.27.2\n  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.7.0) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.7.0) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.7.0) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.7.0) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.7.0) (0.36.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.7.0) (11.3.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (3.20.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2.32.5)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.5.3)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (7.1.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (2.4.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.7.0) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.7.0) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.7.0) (1.2.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers==2.7.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers==2.7.0)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers==2.7.0)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers==2.7.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers==2.7.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers==2.7.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers==2.7.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers==2.7.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers==2.7.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers==2.7.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers==2.7.0) (1.3.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0.0) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2025.10.5)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers==2.7.0) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers==2.7.0) (3.6.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0.0) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==2.7.0) (3.0.3)\nDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, sentence-transformers, accelerate\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.27.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sentence-transformers-2.7.0 tokenizers-0.19.1 transformers-4.44.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import transformers\nimport accelerate\nimport sentence_transformers\n\nprint(f\"✅ Transformers: {transformers.__version__} (Kỳ vọng: 4.44.2)\")\nprint(f\"✅ Accelerate: {accelerate.__version__} (Kỳ vọng: 0.27.2)\")\nprint(f\"✅ Sentence-Transformers: {sentence_transformers.__version__} (Kỳ vọng: 2.7.0)\")\n\ntry:\n    from sentence_transformers import SentenceTransformer\n    # Thử load một model dummy để xem có crash không\n    print(\"🎉 THÀNH CÔNG! Đã import được SentenceTransformer.\")\nexcept Exception as e:\n    print(f\"❌ Vẫn lỗi: {e}\")","metadata":{"id":"JELpfA2u6rri","outputId":"85ba24b4-70cc-4097-c1d1-0c1266377f4f","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:06:02.738077Z","iopub.execute_input":"2025-12-16T11:06:02.738321Z","iopub.status.idle":"2025-12-16T11:06:09.960139Z","shell.execute_reply.started":"2025-12-16T11:06:02.738297Z","shell.execute_reply":"2025-12-16T11:06:09.959517Z"}},"outputs":[{"name":"stdout","text":"✅ Transformers: 4.44.2 (Kỳ vọng: 4.44.2)\n✅ Accelerate: 0.27.2 (Kỳ vọng: 0.27.2)\n✅ Sentence-Transformers: 2.7.0 (Kỳ vọng: 2.7.0)\n🎉 THÀNH CÔNG! Đã import được SentenceTransformer.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\nfrom torch.utils.data import DataLoader\nimport pandas as pd\nimport os\n\n# Tắt chế độ log lên WandB\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"WANDB_MODE\"] = \"disabled\"","metadata":{"id":"05d7230c","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:06:09.960805Z","iopub.execute_input":"2025-12-16T11:06:09.961191Z","iopub.status.idle":"2025-12-16T11:06:10.427463Z","shell.execute_reply.started":"2025-12-16T11:06:09.961172Z","shell.execute_reply":"2025-12-16T11:06:10.426699Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"data_dir = \"/kaggle/input/uitchatbot\"","metadata":{"id":"1ea18dfb","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:06:10.428933Z","iopub.execute_input":"2025-12-16T11:06:10.429274Z","iopub.status.idle":"2025-12-16T11:06:10.432588Z","shell.execute_reply.started":"2025-12-16T11:06:10.429255Z","shell.execute_reply":"2025-12-16T11:06:10.431969Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Data loading","metadata":{"id":"4db204a2"}},{"cell_type":"markdown","source":"## Load DataFrame","metadata":{"id":"0453718e"}},{"cell_type":"code","source":"train_df = pd.read_csv(f\"{data_dir}/train.csv\")\nval_df = pd.read_csv(f\"{data_dir}/val.csv\")\ntest_df = pd.read_csv(f\"{data_dir}/test.csv\")","metadata":{"id":"b40973c8","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:06:10.433152Z","iopub.execute_input":"2025-12-16T11:06:10.433392Z","iopub.status.idle":"2025-12-16T11:06:10.972850Z","shell.execute_reply.started":"2025-12-16T11:06:10.433371Z","shell.execute_reply":"2025-12-16T11:06:10.972284Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(\"Train data:\")\ntrain_df.head()","metadata":{"id":"4mXlRatQg45s","outputId":"e65aefe6-dade-4a38-f037-fa290ab0d022","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:06:10.973590Z","iopub.execute_input":"2025-12-16T11:06:10.973845Z","iopub.status.idle":"2025-12-16T11:06:10.999189Z","shell.execute_reply.started":"2025-12-16T11:06:10.973817Z","shell.execute_reply":"2025-12-16T11:06:10.998632Z"}},"outputs":[{"name":"stdout","text":"Train data:\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   index                                            context  \\\n0   8276  Điều  9.\\tTuyển bổ sung và loại ra khỏi chương...   \n1   8543  Điều  4.        Kiểm tra xếp lớp đầu khóa cho ...   \n2   7152  Điều  5.        Chương trình đào tạo\\nCT CLC đ...   \n3   2218  Điều  25. Cách tính điểm trung bình\\n1.   ĐTBH...   \n4   5361  Điều  19. Tổ chức phúc khảo và giải quyết khiế...   \n\n                                             article  \\\n0  Điều 9. Tuyển bổ sung và loại ra khỏi chương t...   \n1  Điều 4. Kiểm tra xếp lớp đầu khóa cho sinh viê...   \n2                       Điều 5. Chương trình đào tạo   \n3                 Điều 25. Cách tính điểm trung bình   \n4  Điều 19. Tổ chức phúc khảo và giải quyết khiếu...   \n\n                                            document  \\\n0             QUY ĐỊNH ĐÀO TẠO CHƯƠNG TRÌNH TÀI NĂNG   \n1  QUY ĐỊNH ĐÀO TẠO NGOẠI NGỮ ĐỐI VỚI HỆ ĐẠI HỌC ...   \n2       QUY ĐỊNH ĐÀO TẠO CHƯƠNG TRÌNH CHẤT LƯỢNG CAO   \n3  QUY CHẾ ĐÀO TẠO THEO HỌC CHẾ TÍN CHỈ CHO HỆ ĐẠ...   \n4  QUY ĐỊNH Tổ chức thi các môn học hệ đại học ch...   \n\n                                            question  \\\n0  Sinh viên dự bị không trở thành sinh viên chín...   \n1  Các mức điểm xếp lớp tiếng Anh được Hiệu trưởn...   \n2  Trình độ tiếng Nhật đạt N mấy mới thì sinh viê...   \n3  Cách tính điểm giữa điểm trung bình học kỳ, đi...   \n4  Hoạt động nào sẽ diễn ra khi SV có khiếu nại v...   \n\n                                extractive answer  \\\n0                             02 học kỳ liên tiếp   \n1      theo đề xuất hợp lý của bộ phận chuyên môn   \n2                                              N3   \n3  ĐTBHK, ĐTBC và ĐTBCTL được tính theo công thức   \n4                                       phúc khảo   \n\n                                  abstractive answer  yes/no  \n0  Sinh viên dự bị không trở thành sinh viên chín...     NaN  \n1  Các mức điểm xếp lớp tiếng Anh được Hiệu trưởn...     NaN  \n2  Sinh viên CT CLC phải đạt tiếng Nhật N3 thì mớ...     NaN  \n3  Cách tính ĐTBHK, ĐTBC và ĐTBCTL được tính theo...     1.0  \n4  Trường sẽ tổ chức phúc khảo và giải quyết khiế...     NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>context</th>\n      <th>article</th>\n      <th>document</th>\n      <th>question</th>\n      <th>extractive answer</th>\n      <th>abstractive answer</th>\n      <th>yes/no</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8276</td>\n      <td>Điều  9.\\tTuyển bổ sung và loại ra khỏi chương...</td>\n      <td>Điều 9. Tuyển bổ sung và loại ra khỏi chương t...</td>\n      <td>QUY ĐỊNH ĐÀO TẠO CHƯƠNG TRÌNH TÀI NĂNG</td>\n      <td>Sinh viên dự bị không trở thành sinh viên chín...</td>\n      <td>02 học kỳ liên tiếp</td>\n      <td>Sinh viên dự bị không trở thành sinh viên chín...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8543</td>\n      <td>Điều  4.        Kiểm tra xếp lớp đầu khóa cho ...</td>\n      <td>Điều 4. Kiểm tra xếp lớp đầu khóa cho sinh viê...</td>\n      <td>QUY ĐỊNH ĐÀO TẠO NGOẠI NGỮ ĐỐI VỚI HỆ ĐẠI HỌC ...</td>\n      <td>Các mức điểm xếp lớp tiếng Anh được Hiệu trưởn...</td>\n      <td>theo đề xuất hợp lý của bộ phận chuyên môn</td>\n      <td>Các mức điểm xếp lớp tiếng Anh được Hiệu trưởn...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7152</td>\n      <td>Điều  5.        Chương trình đào tạo\\nCT CLC đ...</td>\n      <td>Điều 5. Chương trình đào tạo</td>\n      <td>QUY ĐỊNH ĐÀO TẠO CHƯƠNG TRÌNH CHẤT LƯỢNG CAO</td>\n      <td>Trình độ tiếng Nhật đạt N mấy mới thì sinh viê...</td>\n      <td>N3</td>\n      <td>Sinh viên CT CLC phải đạt tiếng Nhật N3 thì mớ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2218</td>\n      <td>Điều  25. Cách tính điểm trung bình\\n1.   ĐTBH...</td>\n      <td>Điều 25. Cách tính điểm trung bình</td>\n      <td>QUY CHẾ ĐÀO TẠO THEO HỌC CHẾ TÍN CHỈ CHO HỆ ĐẠ...</td>\n      <td>Cách tính điểm giữa điểm trung bình học kỳ, đi...</td>\n      <td>ĐTBHK, ĐTBC và ĐTBCTL được tính theo công thức</td>\n      <td>Cách tính ĐTBHK, ĐTBC và ĐTBCTL được tính theo...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5361</td>\n      <td>Điều  19. Tổ chức phúc khảo và giải quyết khiế...</td>\n      <td>Điều 19. Tổ chức phúc khảo và giải quyết khiếu...</td>\n      <td>QUY ĐỊNH Tổ chức thi các môn học hệ đại học ch...</td>\n      <td>Hoạt động nào sẽ diễn ra khi SV có khiếu nại v...</td>\n      <td>phúc khảo</td>\n      <td>Trường sẽ tổ chức phúc khảo và giải quyết khiế...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## Load train data","metadata":{"id":"0ad0e8c8"}},{"cell_type":"markdown","source":"Dữ liệu train có format là `[Câu hỏi, Context đúng]` với mục đích tìm đúng Context cần thiết để trả lời câu hỏi.","metadata":{"id":"1ff54d88"}},{"cell_type":"code","source":"train_examples = []\nfor index, row in train_df.iterrows():\n    train_examples.append(InputExample(texts = [row[\"question\"], row[\"context\"]]))\n\ntrain_dataloader = DataLoader(train_examples, shuffle = True, batch_size = 16)","metadata":{"id":"3079ac4f","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:06:10.999909Z","iopub.execute_input":"2025-12-16T11:06:11.000186Z","iopub.status.idle":"2025-12-16T11:06:11.300133Z","shell.execute_reply.started":"2025-12-16T11:06:11.000166Z","shell.execute_reply":"2025-12-16T11:06:11.299515Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Prepare Evaluator","metadata":{"id":"f0ed9601"}},{"cell_type":"code","source":"def createEvaluator(df):\n    queries = {}    # id câu hỏi -> nội dung câu hỏi\n    corpus = {}     # id context -> nội dung context\n    relevant_docs = {}  # id câu hỏi -> set các id context đúng\n\n    for index, row in df.iterrows():\n        q_id = f\"q_{index}\"\n        c_id = f\"c_{index}\"\n\n        queries[q_id] = row[\"question\"]\n        corpus[c_id] = row[\"context\"]\n        relevant_docs[q_id] = {c_id}\n\n    evaluator = evaluation.InformationRetrievalEvaluator(\n        queries,\n        corpus,\n        relevant_docs,\n        show_progress_bar = True\n    )\n\n    return evaluator","metadata":{"id":"90c86db2","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:06:11.300830Z","iopub.execute_input":"2025-12-16T11:06:11.301029Z","iopub.status.idle":"2025-12-16T11:06:11.305947Z","shell.execute_reply.started":"2025-12-16T11:06:11.301013Z","shell.execute_reply":"2025-12-16T11:06:11.305204Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"val_evaluator = createEvaluator(val_df)","metadata":{"id":"2b6f985d","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:06:11.306915Z","iopub.execute_input":"2025-12-16T11:06:11.307217Z","iopub.status.idle":"2025-12-16T11:06:11.358909Z","shell.execute_reply.started":"2025-12-16T11:06:11.307200Z","shell.execute_reply":"2025-12-16T11:06:11.358310Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Load pre-trained model and evaluate","metadata":{"id":"4eec994d"}},{"cell_type":"code","source":"MODEL_NAME = \"hiieu/halong_embedding\"","metadata":{"id":"f2691b4c","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:06:11.361051Z","iopub.execute_input":"2025-12-16T11:06:11.361242Z","iopub.status.idle":"2025-12-16T11:06:11.364510Z","shell.execute_reply.started":"2025-12-16T11:06:11.361227Z","shell.execute_reply":"2025-12-16T11:06:11.363795Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"base_model = SentenceTransformer(MODEL_NAME, trust_remote_code=True)","metadata":{"id":"80cb6f79","outputId":"74fbd018-435a-4d2d-c0e3-14f099946ea2","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:06:11.365362Z","iopub.execute_input":"2025-12-16T11:06:11.365625Z","iopub.status.idle":"2025-12-16T11:06:18.548281Z","shell.execute_reply.started":"2025-12-16T11:06:11.365608Z","shell.execute_reply":"2025-12-16T11:06:18.547680Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca5d44bfde8041348b3d4a5fe150b22c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/201 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fa974ea8ed8410e859f524ebb57e4fd"}},"metadata":{}},{"name":"stderr","text":"You try to use a model that was created with version 3.0.1, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n\n\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4fedcf7b1464909a64008831c399432"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f878f38b225a48d4a3566940adfe7531"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f34ed4fa6534fe8b0cda73bcc5e6cb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8189fd50c99646e4a872735ca42c3c64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9117c85146e74647802944eff994754c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c21077a04034dafb31af0e7b4b6898f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16af9464d0f04dba8247e9465f68784d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"098b8486ad934ea2a3d480b096b12f0b"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"base_results = val_evaluator(base_model)\nbase_results = val_evaluator.compute_metrices(base_model)\nprint(\"Các chỉ số đo được:\", base_results.keys())","metadata":{"id":"4c68aa0b","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:06:18.549058Z","iopub.execute_input":"2025-12-16T11:06:18.549344Z","iopub.status.idle":"2025-12-16T11:07:06.310270Z","shell.execute_reply.started":"2025-12-16T11:06:18.549313Z","shell.execute_reply":"2025-12-16T11:07:06.309527Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/31 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fe7de2d97194960a7e7a5b8b04185a5"}},"metadata":{}},{"name":"stderr","text":"Corpus Chunks: 100%|██████████| 1/1 [00:21<00:00, 21.30s/it]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/31 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"600f6a10631645daa038ff1e6a5c1ed7"}},"metadata":{}},{"name":"stderr","text":"Corpus Chunks: 100%|██████████| 1/1 [00:22<00:00, 22.68s/it]","output_type":"stream"},{"name":"stdout","text":"Các chỉ số đo được: dict_keys(['cos_sim', 'dot_score'])\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# Fine-tune model","metadata":{"id":"a453f8bb"}},{"cell_type":"code","source":"train_loss = losses.MultipleNegativesRankingLoss(model = base_model)","metadata":{"id":"94c83ed3","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:07:06.311111Z","iopub.execute_input":"2025-12-16T11:07:06.311394Z","iopub.status.idle":"2025-12-16T11:07:06.315500Z","shell.execute_reply.started":"2025-12-16T11:07:06.311367Z","shell.execute_reply":"2025-12-16T11:07:06.314751Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"num_epochs = 6\nwarmup_steps = int(len(train_dataloader) * num_epochs * 0.1) # 10% of train data for warm-up","metadata":{"id":"27b643ba","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:07:06.316287Z","iopub.execute_input":"2025-12-16T11:07:06.316540Z","iopub.status.idle":"2025-12-16T11:07:06.326004Z","shell.execute_reply.started":"2025-12-16T11:07:06.316520Z","shell.execute_reply":"2025-12-16T11:07:06.325388Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"print(\"Starting training...\")\n\nbase_model.fit(\n    train_objectives = [(train_dataloader, train_loss)],\n    evaluator = val_evaluator,\n    evaluation_steps = 500,\n    epochs = num_epochs,\n    warmup_steps = warmup_steps,\n    output_path = \"/kaggle/working/fine_tuned_model\",\n    save_best_model = True,\n    show_progress_bar = True,\n    use_amp=True\n)\n\nprint(\"Training complete!\")","metadata":{"id":"2834af23","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:07:06.326853Z","iopub.execute_input":"2025-12-16T11:07:06.327094Z","iopub.status.idle":"2025-12-16T11:46:43.252642Z","shell.execute_reply.started":"2025-12-16T11:07:06.327072Z","shell.execute_reply":"2025-12-16T11:46:43.251797Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sentence_transformers/SentenceTransformer.py:1011: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3be38ee3cd6409596037ededc198fec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/488 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97af975ba006402f8b7cf4afc6fbf3ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/31 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c8cd628cfa54ff09831546bc7ebf180"}},"metadata":{}},{"name":"stderr","text":"\nCorpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\nCorpus Chunks: 100%|██████████| 1/1 [00:27<00:00, 27.08s/it]\u001b[A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/488 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d100da41566844a8acd354d050fc7850"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/31 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13ad7279c319426ba974acad6ced0977"}},"metadata":{}},{"name":"stderr","text":"\nCorpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\nCorpus Chunks: 100%|██████████| 1/1 [00:27<00:00, 27.21s/it]\u001b[A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/488 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1829ed9d7374c0595ccfe41a356a291"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/31 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"109faa4716254c6d9ebf2e04e290490b"}},"metadata":{}},{"name":"stderr","text":"\nCorpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\nCorpus Chunks: 100%|██████████| 1/1 [00:27<00:00, 27.07s/it]\u001b[A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/488 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc4481ffc3804735936f7bc9e67fb03d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/31 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a07dd1b95ec4d67b08c595b408a7b32"}},"metadata":{}},{"name":"stderr","text":"\nCorpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\nCorpus Chunks: 100%|██████████| 1/1 [00:27<00:00, 27.22s/it]\u001b[A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/488 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb15d5ebf78b4f2a961a635f0acb6497"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/31 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd8e98b0197640bcbcc6294a272561b0"}},"metadata":{}},{"name":"stderr","text":"\nCorpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\nCorpus Chunks: 100%|██████████| 1/1 [00:27<00:00, 27.34s/it]\u001b[A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Iteration:   0%|          | 0/488 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45da63ff1f7e449b8dc0857ff56a1531"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/31 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff5e24efd2434e6cb79eaf9cb35073ff"}},"metadata":{}},{"name":"stderr","text":"\nCorpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\nCorpus Chunks: 100%|██████████| 1/1 [00:27<00:00, 27.16s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Training complete!\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Compare `base_model` and `fine-tuned model`","metadata":{"id":"dde19e15"}},{"cell_type":"code","source":"test_evaluator = createEvaluator(test_df)","metadata":{"id":"9025805f","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:46:43.253641Z","iopub.execute_input":"2025-12-16T11:46:43.253922Z","iopub.status.idle":"2025-12-16T11:46:43.297213Z","shell.execute_reply.started":"2025-12-16T11:46:43.253894Z","shell.execute_reply":"2025-12-16T11:46:43.296713Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# 1. Vào nhóm Cosine\ncosine_metrics = base_results['cos_sim']\n\n# 2. Vào nhóm MRR và Accuracy (nơi chứa các dict con)\nmrr_bucket = cosine_metrics['mrr@k']\nacc_bucket = cosine_metrics['accuracy@k']\n\n# In thử xem bên trong có những k nào (thường là 1, 3, 5, 10)\nprint(\"Các giá trị k có sẵn:\", list(mrr_bucket.keys()))\n\n# 3. Lấy giá trị tại k=10 (Lưu ý: số nguyên 10, không phải chuỗi \"10\")\nmrr_10 = mrr_bucket.get(10, 0)\nacc_10 = acc_bucket.get(10, 0)\n\nprint(f\"\\n✅ Base Model MRR@10:      {mrr_10:.4f}\")\nprint(f\"✅ Base Model Accuracy@10: {acc_10:.4f}\")","metadata":{"id":"c3d9ccb0","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:46:43.298093Z","iopub.execute_input":"2025-12-16T11:46:43.298320Z","iopub.status.idle":"2025-12-16T11:46:43.303148Z","shell.execute_reply.started":"2025-12-16T11:46:43.298304Z","shell.execute_reply":"2025-12-16T11:46:43.302489Z"}},"outputs":[{"name":"stdout","text":"Các giá trị k có sẵn: [10]\n\n✅ Base Model MRR@10:      0.3334\n✅ Base Model Accuracy@10: 0.7254\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\n# 1. Load model đã train\nfine_tuned_model = SentenceTransformer(\"./fine_tuned_model\")\n\n# 2. Dùng hàm compute_metrices để lấy bảng kết quả đầy đủ\nfine_tuned_results = test_evaluator.compute_metrices(fine_tuned_model)\n\n# 3. Truy cập vào đúng cấu trúc lồng nhau (Nested Dictionary)\n# Cấu trúc: {'cos_sim': {'mrr@k': {10: 0.xxx}, 'accuracy@k': {10: 0.xxx}}}\ncosine_metrics = fine_tuned_results['cos_sim']\nmrr_10 = cosine_metrics['mrr@k'][10]\nacc_10 = cosine_metrics['accuracy@k'][10]\n\n# 4. In kết quả\nprint(f\"\\n✅ Fine-tuned Model MRR@10:      {mrr_10:.4f}\")\nprint(f\"✅ Fine-tuned Model Accuracy@10: {acc_10:.4f}\")","metadata":{"id":"f6fc3437","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:46:43.303909Z","iopub.execute_input":"2025-12-16T11:46:43.304120Z","iopub.status.idle":"2025-12-16T11:47:13.799504Z","shell.execute_reply.started":"2025-12-16T11:46:43.304098Z","shell.execute_reply":"2025-12-16T11:47:13.798675Z"}},"outputs":[{"name":"stderr","text":"You try to use a model that was created with version 3.0.1, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n\n\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/31 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c23b5af938644ce9846f93dafc560823"}},"metadata":{}},{"name":"stderr","text":"Corpus Chunks: 100%|██████████| 1/1 [00:27<00:00, 27.61s/it]","output_type":"stream"},{"name":"stdout","text":"\n✅ Fine-tuned Model MRR@10:      0.4110\n✅ Fine-tuned Model Accuracy@10: 0.8381\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"print(\"So sánh Base Model và Fine-tuned Model trên tập Test:\")\n\n# 1. Lấy chỉ số MRR@10 của Base Model (từ biến base_results đã chạy trước đó)\n# Cấu trúc: ['cos_sim']['mrr@k'][10]\nbase_mrr = base_results['cos_sim']['mrr@k'][10]\n\n# 2. Lấy chỉ số MRR@10 của Fine-tuned Model\n# Lưu ý: Phải đảm bảo fine_tuned_results được tạo từ hàm .compute_metrices()\nfine_tuned_mrr = fine_tuned_results['cos_sim']['mrr@k'][10]\n\n# 3. Tính độ cải thiện\nimprovement = fine_tuned_mrr - base_mrr\n\n# 4. In kết quả\nprint(f\"Base Model MRR@10:       {base_mrr:.4f}\")\nprint(f\"Fine-tuned Model MRR@10: {fine_tuned_mrr:.4f}\")\nprint(f\"---------------------------------------\")\nprint(f\"🚀 Mức độ cải thiện:     {improvement:+.4f}\")\n\nif improvement > 0:\n    print(\"✅ Chúc mừng! Model fine-tune đã hoạt động hiệu quả hơn.\")\nelse:\n    print(\"⚠️ Model chưa cải thiện. Có thể do tập train quá ít hoặc hyperparameters chưa chuẩn.\")","metadata":{"id":"8a3af741","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:47:13.800405Z","iopub.execute_input":"2025-12-16T11:47:13.801012Z","iopub.status.idle":"2025-12-16T11:47:13.806013Z","shell.execute_reply.started":"2025-12-16T11:47:13.800989Z","shell.execute_reply":"2025-12-16T11:47:13.805331Z"}},"outputs":[{"name":"stdout","text":"So sánh Base Model và Fine-tuned Model trên tập Test:\nBase Model MRR@10:       0.3334\nFine-tuned Model MRR@10: 0.4110\n---------------------------------------\n🚀 Mức độ cải thiện:     +0.0776\n✅ Chúc mừng! Model fine-tune đã hoạt động hiệu quả hơn.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"!zip -r /kaggle/working/chroma_db.zip /kaggle/working/chroma_db","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:23:43.702034Z","iopub.execute_input":"2025-12-16T12:23:43.702288Z","iopub.status.idle":"2025-12-16T12:24:01.028278Z","shell.execute_reply.started":"2025-12-16T12:23:43.702272Z","shell.execute_reply":"2025-12-16T12:24:01.027380Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/chroma_db/ (stored 0%)\n  adding: kaggle/working/chroma_db/f66da26c-f2c8-4dc8-9e6c-ba5af52fb019/ (stored 0%)\n  adding: kaggle/working/chroma_db/f66da26c-f2c8-4dc8-9e6c-ba5af52fb019/data_level0.bin","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 9%)\n  adding: kaggle/working/chroma_db/f66da26c-f2c8-4dc8-9e6c-ba5af52fb019/length.bin (deflated 100%)\n  adding: kaggle/working/chroma_db/f66da26c-f2c8-4dc8-9e6c-ba5af52fb019/link_lists.bin (deflated 75%)\n  adding: kaggle/working/chroma_db/f66da26c-f2c8-4dc8-9e6c-ba5af52fb019/index_metadata.pickle (deflated 44%)\n  adding: kaggle/working/chroma_db/f66da26c-f2c8-4dc8-9e6c-ba5af52fb019/header.bin (deflated 54%)\n  adding: kaggle/working/chroma_db/chroma.sqlite3 (deflated 49%)\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"!zip -r /kaggle/working/fine_tuned_model_0_8.zip /kaggle/working/fine_tuned_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:47:13.806673Z","iopub.execute_input":"2025-12-16T11:47:13.806887Z","iopub.status.idle":"2025-12-16T11:49:25.845016Z","shell.execute_reply.started":"2025-12-16T11:47:13.806863Z","shell.execute_reply":"2025-12-16T11:49:25.843824Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"  adding: kaggle/working/fine_tuned_model/ (stored 0%)\n  adding: kaggle/working/fine_tuned_model/README.md (deflated 55%)\n  adding: kaggle/working/fine_tuned_model/model.safetensors (deflated 25%)\n  adding: kaggle/working/fine_tuned_model/special_tokens_map.json (deflated 85%)\n  adding: kaggle/working/fine_tuned_model/sentence_bert_config.json (deflated 4%)\n  adding: kaggle/working/fine_tuned_model/config.json (deflated 50%)\n  adding: kaggle/working/fine_tuned_model/tokenizer_config.json (deflated 75%)\n  adding: kaggle/working/fine_tuned_model/1_Pooling/ (stored 0%)\n  adding: kaggle/working/fine_tuned_model/1_Pooling/config.json (deflated 57%)\n  adding: kaggle/working/fine_tuned_model/config_sentence_transformers.json (deflated 35%)\n  adding: kaggle/working/fine_tuned_model/modules.json (deflated 62%)\n  adding: kaggle/working/fine_tuned_model/2_Normalize/ (stored 0%)\n  adding: kaggle/working/fine_tuned_model/eval/ (stored 0%)\n  adding: kaggle/working/fine_tuned_model/eval/Information-Retrieval_evaluation_results.csv (deflated 74%)\n  adding: kaggle/working/fine_tuned_model/tokenizer.json (deflated 76%)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# Re-rank","metadata":{"id":"FXAnKWFYRP46"}},{"cell_type":"code","source":"import os\nimport sys\n\n# Lệnh cài đặt \"Golden Stack\" ổn định nhất\nif \"kaggle_web_client\" in sys.modules or \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:\n    print(\"--- Đang cài đặt thư viện cho Kaggle ---\")\n    os.system('pip install -q -U langchain==0.1.20 langchain-community==0.0.38 langchain-core==0.1.52 langchain-google-genai==1.0.3 transformers==4.41.2 sentence-transformers==2.7.0 accelerate==0.30.1 chromadb==0.5.0 rank_bm25==0.2.2 \"numpy<2.0.0\"')\n    os.system('pip install -q rank_bm25')\n    # Cài đè pandas để fix lỗi numpy binary incompatibility\n    os.system('pip install -q \"numpy<2.0.0\" pandas --force-reinstall')\n    os.system('pip install -q rouge-score scikit-learn tqdm')\n    print(\"✅ Cài đặt hoàn tất!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:49:25.846455Z","iopub.execute_input":"2025-12-16T11:49:25.846842Z","iopub.status.idle":"2025-12-16T11:50:41.050261Z","shell.execute_reply.started":"2025-12-16T11:49:25.846815Z","shell.execute_reply":"2025-12-16T11:50:41.049448Z"}},"outputs":[{"name":"stdout","text":"--- Đang cài đặt thư viện cho Kaggle ---\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.8/43.8 kB 1.6 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.3/67.3 kB 4.4 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 20.1 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 54.1 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 302.9/302.9 kB 25.9 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.1/9.1 MB 105.7 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 302.6/302.6 kB 26.5 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 526.8/526.8 kB 37.6 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 91.6 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 278.2/278.2 kB 24.2 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 150.7/150.7 kB 13.1 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 679.1/679.1 kB 43.9 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 88.0 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 311.8/311.8 kB 22.9 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 103.1/103.1 kB 9.3 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.4/17.4 MB 86.1 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.9/294.9 kB 21.0 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.5/52.5 kB 4.2 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 149.7/149.7 kB 12.8 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.0/64.0 kB 6.0 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 9.3 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 4.2 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 145.2/145.2 kB 14.1 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 456.6/456.6 kB 36.6 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.4/128.4 kB 12.4 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 90.8 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 456.1/456.1 kB 32.5 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 3.0 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 6.8 MB/s eta 0:00:00\n","output_type":"stream"},{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ngoogle-adk 1.18.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.27.0 which is incompatible.\ngoogle-adk 1.18.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.27.0 which is incompatible.\ngoogle-adk 1.18.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 4.25.8 which is incompatible.\nopentelemetry-resourcedetector-gcp 1.11.0a0 requires opentelemetry-api~=1.30, but you have opentelemetry-api 1.27.0 which is incompatible.\nopentelemetry-resourcedetector-gcp 1.11.0a0 requires opentelemetry-sdk~=1.30, but you have opentelemetry-sdk 1.27.0 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nopentelemetry-exporter-gcp-monitoring 1.11.0a0 requires opentelemetry-api~=1.30, but you have opentelemetry-api 1.27.0 which is incompatible.\nopentelemetry-exporter-gcp-monitoring 1.11.0a0 requires opentelemetry-sdk~=1.30, but you have opentelemetry-sdk 1.27.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.27.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.27.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.27.0 which is incompatible.\nopentelemetry-exporter-gcp-trace 1.11.0 requires opentelemetry-api~=1.30, but you have opentelemetry-api 1.27.0 which is incompatible.\nopentelemetry-exporter-gcp-trace 1.11.0 requires opentelemetry-sdk~=1.30, but you have opentelemetry-sdk 1.27.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nopentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-api>=1.35.0, but you have opentelemetry-api 1.27.0 which is incompatible.\nopentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.27.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngoogle-cloud-bigquery 3.35.1 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\nxarray 2025.7.1 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ndb-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n","output_type":"stream"},{"name":"stdout","text":"     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.0/61.0 kB 2.2 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 91.2/91.2 kB 5.8 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.3/18.3 MB 91.1 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 107.6 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.9/229.9 kB 19.4 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 509.2/509.2 kB 37.3 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 348.5/348.5 kB 26.5 MB/s eta 0:00:00\n","output_type":"stream"},{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\ncudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ngoogle-adk 1.18.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.27.0 which is incompatible.\ngoogle-adk 1.18.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.27.0 which is incompatible.\ngoogle-adk 1.18.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\ns3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2025.10.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.1.0 which is incompatible.\ngoogle-cloud-bigquery 3.35.1 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\nxarray 2025.7.1 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ndb-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n","output_type":"stream"},{"name":"stdout","text":"✅ Cài đặt hoàn tất!\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import shutil\nimport time\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom sentence_transformers import SentenceTransformer, util\nfrom rouge_score import rouge_scorer\nimport os\n\n# 1. Import Core\nfrom langchain_core.documents import Document\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\n\n# 2. Import Text Splitter\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n\n# 3. Import Community (VectorStore & Embeddings)\nfrom langchain_community.vectorstores import Chroma\n# Lưu ý: Bản ổn định dùng import này, KHÔNG dùng langchain_huggingface\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\n\n# 4. Import Google Gemini\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\n# 5. Import Retrieval & Re-ranking\nfrom langchain.retrievers import ContextualCompressionRetriever\nfrom langchain.retrievers.document_compressors import CrossEncoderReranker\nfrom langchain_community.cross_encoders import HuggingFaceCrossEncoder\n\nfrom langchain.retrievers import EnsembleRetriever\nfrom langchain_community.retrievers import BM25Retriever","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:50:41.051243Z","iopub.execute_input":"2025-12-16T11:50:41.051541Z","iopub.status.idle":"2025-12-16T11:50:46.381638Z","shell.execute_reply.started":"2025-12-16T11:50:41.051516Z","shell.execute_reply":"2025-12-16T11:50:46.381028Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"FINE_TUNED_MODEL_PATH = \"/kaggle/working/fine_tuned_model\"\nDATA_PATH= \"/kaggle/input/uitchatbot\"\nCHROMA_DB_PATH = \"/kaggle/working/chroma_db\"","metadata":{"id":"geQ2teBzRTsk","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:50:46.382405Z","iopub.execute_input":"2025-12-16T11:50:46.382959Z","iopub.status.idle":"2025-12-16T11:50:46.386410Z","shell.execute_reply.started":"2025-12-16T11:50:46.382934Z","shell.execute_reply":"2025-12-16T11:50:46.385731Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def buildVectorDB(docs):\n    \"\"\"\n    Hàm này đọc dữ liệu, vector hóa và lưu vào ChromaDB.\n    Chỉ cần chạy 1 lần hoặc khi dữ liệu thay đổi.\n    \"\"\"\n    print(\"--- BẮT ĐẦU XÂY DỰNG DATABASE ---\")\n\n    # 1. Kiểm tra model fine-tune\n    if not os.path.exists(FINE_TUNED_MODEL_PATH):\n        raise FileNotFoundError(f\"Không tìm thấy model tại {FINE_TUNED_MODEL_PATH}. Hãy train model trước!\")\n\n    # 2. Xóa DB cũ để tránh dữ liệu bị chồng chéo (quan trọng khi đổi model embedding)\n    if os.path.exists(CHROMA_DB_PATH):\n        print(f\"Đang xóa DB cũ tại {CHROMA_DB_PATH}...\")\n        shutil.rmtree(CHROMA_DB_PATH)\n\n    # 3. Chia nhỏ văn bản (Chunking)\n    # Vì context luật thường dài, cần chia nhỏ để model xử lý tốt hơn\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=100)\n    splits = text_splitter.split_documents(docs)\n    print(f\"Đã chia thành {len(splits)} chunks.\")\n\n    # 5. Khởi tạo Embedding Model (Dùng model Fine-tuned)\n    print(\"Đang tải model Embedding Fine-tuned...\")\n    embedding_model = HuggingFaceEmbeddings(\n        model_name=FINE_TUNED_MODEL_PATH,\n        model_kwargs={'device': 'cuda'}, # Đổi thành 'cuda' nếu có GPU\n        encode_kwargs={'normalize_embeddings': True}\n    )\n\n    # 6. Tạo và Lưu Vector Store\n    print(\"Đang tạo Vector Store (ChromaDB)... quá trình này có thể mất vài phút.\")\n    vectorstore = Chroma.from_documents(\n        documents=splits,\n        embedding=embedding_model,\n        persist_directory=CHROMA_DB_PATH\n    )\n    vectorstore.persist()\n    print(\"✅ Đã xây dựng xong Vector Database!\")\n    return vectorstore","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:50:46.387239Z","iopub.execute_input":"2025-12-16T11:50:46.387582Z","iopub.status.idle":"2025-12-16T11:50:46.398269Z","shell.execute_reply.started":"2025-12-16T11:50:46.387557Z","shell.execute_reply":"2025-12-16T11:50:46.397702Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"print(\"Đang đọc file CSV...\")\ndf = pd.read_csv(f\"{DATA_PATH}/train.csv\")\n# Lọc bỏ dòng trống\ndf = df.dropna(subset=['context', 'question'])\n\n# Chuyển đổi sang Document của LangChain\ndocs = []\nfor _, row in df.iterrows():\n    docs.append(Document(\n        page_content=row['context'],\n        metadata={\n            \"source\": row.get('document', 'N/A'),\n            \"article\": row.get('article', 'N/A')\n        }\n    ))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:50:46.398983Z","iopub.execute_input":"2025-12-16T11:50:46.399357Z","iopub.status.idle":"2025-12-16T11:50:47.129176Z","shell.execute_reply.started":"2025-12-16T11:50:46.399341Z","shell.execute_reply":"2025-12-16T11:50:47.128643Z"}},"outputs":[{"name":"stdout","text":"Đang đọc file CSV...\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"bm25_retriever = BM25Retriever.from_documents(docs) \nbm25_retriever.k = 30  # Lấy 30 doc tốt nhất theo từ khóa","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:50:47.130240Z","iopub.execute_input":"2025-12-16T11:50:47.130518Z","iopub.status.idle":"2025-12-16T11:50:48.563362Z","shell.execute_reply.started":"2025-12-16T11:50:47.130490Z","shell.execute_reply":"2025-12-16T11:50:48.562796Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# ... (Các phần import giữ nguyên) ...\n\n# 1. KHỞI TẠO RETRIEVER\nprint(\"⚙️ Đang tải Retriever...\")\n\n# --- SETUP EMBEDDING (Giữ nguyên) ---\nembedding_model = HuggingFaceEmbeddings(\n    model_name=FINE_TUNED_MODEL_PATH,\n    model_kwargs={'device': 'cuda'},\n    encode_kwargs={'normalize_embeddings': True}\n)\n\nif not os.path.exists(CHROMA_DB_PATH):\n    print(\"Chưa thấy Database, đang tạo mới...\")\n    vectorstore = buildVectorDB(docs)\nelse:\n    print(\"Đã tìm thấy Database, bỏ qua bước tạo mới.\")\n    vectorstore = Chroma(\n        persist_directory=CHROMA_DB_PATH,\n        embedding_function=embedding_model\n    )\n\n# --- SETUP BASE RETRIEVERS (Giữ nguyên) ---\nchroma_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 20}) # Lấy top 20 thô\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, chroma_retriever],\n    weights=[0.5, 0.5]\n)\n\n# --- THAY ĐỔI QUAN TRỌNG Ở ĐÂY (RERANKER MỚI) ---\nprint(\"🚀 Đang load Reranker Model: BAAI/bge-reranker-v2-m3 ...\")\n\n# Thay thế ms-marco-MiniLM (tiếng Anh) bằng BGE-M3 (Đa ngôn ngữ/Tiếng Việt)\ncross_encoder = HuggingFaceCrossEncoder(\n    model_name=\"BAAI/bge-reranker-v2-m3\", \n    model_kwargs={'device': 'cuda'}  # Bắt buộc: Ép chạy bằng GPU để không bị chậm\n)\n\n# Lấy top 3 kết quả tốt nhất sau khi rerank\ncompressor = CrossEncoderReranker(model=cross_encoder, top_n=3)\n\n# Đây là bộ máy tìm kiếm hoàn chỉnh\nretriever = ContextualCompressionRetriever(\n    base_compressor=compressor,\n    base_retriever=ensemble_retriever\n)\n\n# 2. HÀM ĐÁNH GIÁ (Giữ nguyên logic cũ)\ndef evaluate_retrieval_only(csv_path):\n    print(f\"📖 Đang đọc file: {csv_path}\")\n    df = pd.read_csv(csv_path)\n    \n    hits = 0            \n    mrr_sum = 0         \n    total = len(df)\n    \n    print(f\"🚀 Bắt đầu đánh giá {total} câu hỏi (Với BGE-Reranker)...\")\n    \n    for index, row in tqdm(df.iterrows(), total=total):\n        question = str(row['question'])\n        target_article = str(row['article']).strip().lower()\n        \n        if not target_article or target_article == \"nan\":\n            total -= 1\n            continue\n\n        try:\n            # Invoke retriever (Đã bao gồm Rerank)\n            retrieved_docs = retriever.invoke(question)\n            \n            is_found = False\n            rank_score = 0\n            \n            for rank, doc in enumerate(retrieved_docs):\n                found_article = str(doc.metadata.get('article', '')).strip().lower()\n                \n                if target_article in found_article or found_article in target_article:\n                    is_found = True\n                    rank_score = 1 / (rank + 1)\n                    break\n            \n            if is_found:\n                hits += 1\n                mrr_sum += rank_score\n                \n        except Exception as e:\n            print(f\"Lỗi dòng {index}: {e}\")\n\n    if total == 0: total = 1\n    hit_rate = hits / total\n    mrr_score = mrr_sum / total\n    \n    print(\"\\n\" + \"=\"*40)\n    print(\"📊 KẾT QUẢ ĐÁNH GIÁ (MODEL: BAAI/bge-reranker-v2-m3)\")\n    print(\"=\"*40)\n    print(f\"✅ Hit Rate (Recall): {hit_rate:.2%} (Mục tiêu: > 85%)\")\n    print(f\"✅ MRR Score:        {mrr_score:.4f} (Mục tiêu: > 0.7)\")\n    print(\"=\"*40)\n\nif __name__ == \"__main__\":\n    evaluate_retrieval_only(\"/kaggle/input/uitchatbot/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:14:20.215189Z","iopub.execute_input":"2025-12-16T12:14:20.215942Z","iopub.status.idle":"2025-12-16T12:23:43.700326Z","shell.execute_reply.started":"2025-12-16T12:14:20.215913Z","shell.execute_reply":"2025-12-16T12:23:43.699578Z"}},"outputs":[{"name":"stderr","text":"You try to use a model that was created with version 3.0.1, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n\n\n\n","output_type":"stream"},{"name":"stdout","text":"⚙️ Đang tải Retriever...\n","output_type":"stream"},{"name":"stderr","text":"Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\nFailed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n","output_type":"stream"},{"name":"stdout","text":"Đã tìm thấy Database, bỏ qua bước tạo mới.\n🚀 Đang load Reranker Model: BAAI/bge-reranker-v2-m3 ...\n📖 Đang đọc file: /kaggle/input/uitchatbot/test.csv\n🚀 Bắt đầu đánh giá 976 câu hỏi (Với BGE-Reranker)...\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 24/976 [00:12<06:46,  2.34it/s]Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n100%|██████████| 976/976 [09:20<00:00,  1.74it/s]","output_type":"stream"},{"name":"stdout","text":"\n========================================\n📊 KẾT QUẢ ĐÁNH GIÁ (MODEL: BAAI/bge-reranker-v2-m3)\n========================================\n✅ Hit Rate (Recall): 83.91% (Mục tiêu: > 85%)\n✅ MRR Score:        0.8033 (Mục tiêu: > 0.7)\n========================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":28}]}